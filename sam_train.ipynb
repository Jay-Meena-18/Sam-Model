{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu124\n",
      "Torchvision version: 0.19.1+cu124\n",
      "CUDA is available: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jayme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/segment-anything.git'\": Expected package name at the start of dependency specifier\n",
      "    'git+https://github.com/facebookresearch/segment-anything.git'\n",
      "    ^\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python matplotlib\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "    \n",
    "!mkdir images\n",
    "!wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
    "        \n",
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"D:\\\\ML\\\\fruits-360\\\\Training\\\\Apple\\\\0_100 (9).jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "masks = mask_generator.generate(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-labeling completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "# Load the SAM model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"D:\\\\ML\\\\sam_vit_h_4b8939.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "# Directories\n",
    "input_folder = \"D:\\\\ML\\\\fruits-360\\\\xyz\"  # Replace with your image folder path\n",
    "output_folder = \"D:\\\\ML\\\\fruits-360\\\\label\"  # Replace with your output folder path\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded properly\n",
    "        if image is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Generate masks using SAM\n",
    "        masks = mask_generator.generate(image)\n",
    "\n",
    "        # Process each mask\n",
    "        for i, mask in enumerate(masks):\n",
    "            # Save the mask as a binary image\n",
    "            mask_output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_mask_{i}.png\")\n",
    "            cv2.imwrite(mask_output_path, mask['segmentation'].astype(np.uint8) * 255)\n",
    "\n",
    "            # Get the mask segmentation\n",
    "            segmentation = mask['segmentation']\n",
    "\n",
    "            # Find contours of the mask\n",
    "            contours, _ = cv2.findContours(segmentation.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Process each contour to get bounding boxes\n",
    "            for contour in contours:\n",
    "                # Get bounding box coordinates\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Calculate YOLO format (normalized values)\n",
    "                img_height, img_width = image.shape[:2]\n",
    "                x_center = (x + w / 2) / img_width\n",
    "                y_center = (y + h / 2) / img_height\n",
    "                width = w / img_width\n",
    "                height = h / img_height\n",
    "\n",
    "                # Save the YOLO format annotation\n",
    "                yolo_annotation_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "                with open(yolo_annotation_path, 'a') as f:  # Append mode to add all masks to the same file\n",
    "                    # Assuming class_id is 0 for all masks. Change it as needed.\n",
    "                    class_id = 0\n",
    "                    f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "print(\"Auto-labeling completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-labeling completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "# Load the SAM model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"D:\\\\ML\\\\sam_vit_h_4b8939.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "# Directories\n",
    "input_folder =\"D:\\\\ML\\\\fruits-360\\\\xyz\"  # Replace with your image folder path\n",
    "output_folder = \"D:\\\\ML\\\\fruits-360\\\\label\"  # Replace with your output folder path\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded properly\n",
    "        if image is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Generate masks using SAM\n",
    "        masks = mask_generator.generate(image)\n",
    "\n",
    "        # Save each mask as a binary image\n",
    "        for i, mask in enumerate(masks):\n",
    "            mask_output_path = os.path.join(output_folder, f\"{filename}_mask_{i}.png\")\n",
    "            cv2.imwrite(mask_output_path, mask['segmentation'].astype(np.uint8) * 255)\n",
    "\n",
    "print(\"Auto-labeling completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-labeling completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "# Load the SAM model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"D:\\\\ML\\\\sam_vit_h_4b8939.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "# Directories\n",
    "input_folder = \"D:\\\\ML\\\\fruits-360\\\\xyz\"  # Replace with your image folder path\n",
    "output_folder = \"D:\\\\ML\\\\fruits-360\\\\label\"  # Replace with your output folder path\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded properly\n",
    "        if image is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Generate masks using SAM\n",
    "        masks = mask_generator.generate(image)\n",
    "\n",
    "        # Prepare to save annotations\n",
    "        annotations = []\n",
    "\n",
    "        # Save each mask as a binary image and generate YOLO annotations\n",
    "        for i, mask in enumerate(masks):\n",
    "            mask_array = mask['segmentation']\n",
    "            class_id = 0  # Assuming a single class for all masks; change as necessary\n",
    "\n",
    "            # Find contours of the mask\n",
    "            contours, _ = cv2.findContours(mask_array.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for contour in contours:\n",
    "                # Get the bounding box for each contour\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Calculate YOLO format values\n",
    "                img_height, img_width = image.shape[:2]\n",
    "                x_center = (x + w / 2) / img_width\n",
    "                y_center = (y + h / 2) / img_height\n",
    "                width = w / img_width\n",
    "                height = h / img_height\n",
    "\n",
    "                # Append the annotation\n",
    "                annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "        # Save annotations to a text file\n",
    "        annotation_file_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(annotation_file_path, 'w') as f:\n",
    "            for annotation in annotations:\n",
    "                f.write(annotation + '\\n')\n",
    "\n",
    "print(\"Auto-labeling completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO annotations created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def create_yolo_annotation(image_path, class_id, save_path):\n",
    "    \"\"\"\n",
    "    Create YOLO annotation file for a bounding box that covers the whole image.\n",
    "    \n",
    "    YOLO format: <class_id> <x_center> <y_center> <width> <height>\n",
    "    All values are normalized between 0 and 1.\n",
    "    \"\"\"\n",
    "    # Read the image to get its dimensions\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "        return\n",
    "    \n",
    "    img_height, img_width, _ = img.shape\n",
    "    \n",
    "    # Full image bounding box (normalized)\n",
    "    x_center = 0.5\n",
    "    y_center = 0.5\n",
    "    width = 1.0\n",
    "    height = 1.0\n",
    "    \n",
    "    # Prepare the annotation string\n",
    "    annotation = f\"{class_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "    \n",
    "    # Save the annotation to the corresponding .txt file\n",
    "    label_file = os.path.join(save_path, os.path.splitext(os.path.basename(image_path))[0] + \".txt\")\n",
    "    with open(label_file, 'w') as file:\n",
    "        file.write(annotation)\n",
    "\n",
    "def main(training_folder):\n",
    "    \"\"\"\n",
    "    Main function to traverse the training folder and create YOLO annotations.\n",
    "    Each subfolder will be assigned a different class ID.\n",
    "    \"\"\"\n",
    "    # Get all subfolders in the training folder\n",
    "    subfolders = [f.path for f in os.scandir(training_folder) if f.is_dir()]\n",
    "    class_id_mapping = {subfolder: idx for idx, subfolder in enumerate(subfolders)}\n",
    "\n",
    "    # Create an output directory for the labels if not exists\n",
    "    label_output_folder = os.path.join(training_folder, \"labels\")\n",
    "    if not os.path.exists(label_output_folder):\n",
    "        os.makedirs(label_output_folder)\n",
    "\n",
    "    # Traverse each subfolder\n",
    "    for subfolder in subfolders:\n",
    "        class_id = class_id_mapping[subfolder]\n",
    "        class_name = os.path.basename(subfolder)  # Get the class name from the subfolder path\n",
    "\n",
    "        # Create a subfolder in labels for this class if it doesn't exist\n",
    "        class_label_folder = os.path.join(label_output_folder, class_name)\n",
    "        if not os.path.exists(class_label_folder):\n",
    "            os.makedirs(class_label_folder)\n",
    "\n",
    "        image_files = [f for f in os.listdir(subfolder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(subfolder, image_file)\n",
    "\n",
    "            # Create YOLO annotation for the whole image\n",
    "            create_yolo_annotation(image_path, class_id, class_label_folder)\n",
    "\n",
    "    print(\"YOLO annotations created successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    training_folder = \"D:\\\\ML\\\\fruits-360\\\\Training\\\\images\"\n",
    "    main(training_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.17  Python-3.12.3 torch-2.4.1+cu124 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mML\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mYOLOV\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFruit_11\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    794\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:103\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(cfg, overrides)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_resume(overrides)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\torch_utils.py:192\u001b[0m, in \u001b[0;36mselect_device\u001b[1;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[0;32m    185\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39minfo(s)\n\u001b[0;32m    186\u001b[0m         install \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requested.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or pass valid CUDA device(s) if available,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0,1,2,3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     devices \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "model.train(data = \"D:\\\\ML\\\\YOLOV\\\\Fruit_11\\\\data.yaml\" , epochs = 50 , device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Ultralytics YOLOv8.0.81  Python-3.12.3 torch-2.4.1+cu124 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): True\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mML\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain13\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform prediction on all images in the specified folder and save the results\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mML\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mxyz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:249\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m overrides\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m TASK_MAP[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask][\u001b[38;5;241m3\u001b[39m](overrides\u001b[38;5;241m=\u001b[39moverrides, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs, overrides)\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py:274\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[1;34m(self, model, verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize YOLO model with given parameters and set it to evaluation mode.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# half precision only supported on CUDA\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\yolo\\utils\\torch_utils.py:69\u001b[0m, in \u001b[0;36mselect_device\u001b[1;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[0;32m     66\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39minfo(s)\n\u001b[0;32m     67\u001b[0m         install \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requested.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or pass valid CUDA device(s) if available,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0,1,2,3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     73\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     74\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     devices \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# range(torch.cuda.device_count())  # i.e. 0,1,6,7\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): True\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(\"D:\\\\ML\\\\runs\\\\detect\\\\train13\\\\weights\\\\best.pt\")\n",
    "\n",
    "# Perform prediction on all images in the specified folder and save the results\n",
    "results = model.predict(source=\"D:\\\\ML\\\\xyz\",  save=True , device =0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to load grounding dino directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Labeling D:\\ML\\xyz\\0_100 (10).jpg:   0%|          | 0/19 [00:00<?, ?it/s]The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "None of the inputs have requires_grad=True. Gradients will be None\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Labeling D:\\ML\\xyz\\0_100.jpg:   5%|▌         | 1/19 [00:15<04:31, 15.10s/it]     The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "None of the inputs have requires_grad=True. Gradients will be None\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Labeling D:\\ML\\xyz\\Royal-Gala_065.jpg: 100%|██████████| 19/19 [02:18<00:00,  7.31s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset created - ready for distillation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DetectionDataset(classes=['Apple'], images={'0_100 (10).jpg': array([[[255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        [253, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        [253, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '0_100.jpg': array([[[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 254, 255],\n",
       "        [255, 254, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '10_100 (11).jpg': array([[[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '10_100 (7).jpg': array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '13_100 (7).jpg': array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '1_100 (10).jpg': array([[[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '1_100.jpg': array([[[255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 254],\n",
       "        [255, 255, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), '9_100.jpg': array([[[251, 254, 255],\n",
       "        [251, 254, 255],\n",
       "        [255, 254, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[251, 254, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 254, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[253, 255, 255],\n",
       "        [253, 255, 255],\n",
       "        [255, 254, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8), 'Pink-Lady_017.jpg': array([[[ 34,  40, 117],\n",
       "        [ 36,  42, 117],\n",
       "        [ 38,  47, 121],\n",
       "        ...,\n",
       "        [ 69,  72, 187],\n",
       "        [ 79,  81, 199],\n",
       "        [ 84,  86, 204]],\n",
       "\n",
       "       [[ 33,  39, 116],\n",
       "        [ 37,  43, 118],\n",
       "        [ 39,  48, 122],\n",
       "        ...,\n",
       "        [ 70,  73, 188],\n",
       "        [ 78,  80, 198],\n",
       "        [ 81,  83, 201]],\n",
       "\n",
       "       [[ 33,  39, 116],\n",
       "        [ 37,  43, 118],\n",
       "        [ 40,  49, 123],\n",
       "        ...,\n",
       "        [ 67,  73, 186],\n",
       "        [ 72,  77, 192],\n",
       "        [ 73,  78, 193]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 39,  81, 124],\n",
       "        [ 42,  79, 123],\n",
       "        [ 50,  82, 123],\n",
       "        ...,\n",
       "        [ 20,  18,  60],\n",
       "        [ 20,  18,  64],\n",
       "        [ 21,  18,  67]],\n",
       "\n",
       "       [[ 44,  86, 128],\n",
       "        [ 44,  83, 122],\n",
       "        [ 52,  82, 123],\n",
       "        ...,\n",
       "        [ 22,  19,  64],\n",
       "        [ 22,  19,  68],\n",
       "        [ 22,  19,  69]],\n",
       "\n",
       "       [[ 44,  87, 126],\n",
       "        [ 42,  81, 120],\n",
       "        [ 48,  79, 118],\n",
       "        ...,\n",
       "        [ 23,  20,  66],\n",
       "        [ 23,  20,  69],\n",
       "        [ 24,  21,  71]]], dtype=uint8), 'Pink-Lady_018.jpg': array([[[ 53,  56, 137],\n",
       "        [ 46,  49, 130],\n",
       "        [ 40,  44, 125],\n",
       "        ...,\n",
       "        [156, 193, 243],\n",
       "        [147, 187, 239],\n",
       "        [132, 174, 227]],\n",
       "\n",
       "       [[ 56,  59, 140],\n",
       "        [ 47,  50, 131],\n",
       "        [ 41,  44, 125],\n",
       "        ...,\n",
       "        [151, 191, 240],\n",
       "        [141, 181, 234],\n",
       "        [123, 167, 221]],\n",
       "\n",
       "       [[ 63,  64, 145],\n",
       "        [ 51,  54, 135],\n",
       "        [ 41,  43, 127],\n",
       "        ...,\n",
       "        [145, 185, 237],\n",
       "        [128, 169, 224],\n",
       "        [111, 156, 213]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 32,  28, 104],\n",
       "        [ 33,  29, 104],\n",
       "        [ 34,  30, 106],\n",
       "        ...,\n",
       "        [ 92, 172, 201],\n",
       "        [103, 181, 210],\n",
       "        [109, 188, 215]],\n",
       "\n",
       "       [[ 31,  26, 101],\n",
       "        [ 31,  27,  99],\n",
       "        [ 32,  27, 102],\n",
       "        ...,\n",
       "        [ 89, 168, 201],\n",
       "        [101, 178, 210],\n",
       "        [107, 185, 214]],\n",
       "\n",
       "       [[ 30,  26,  98],\n",
       "        [ 30,  26,  98],\n",
       "        [ 31,  27,  99],\n",
       "        ...,\n",
       "        [ 87, 166, 199],\n",
       "        [100, 177, 210],\n",
       "        [106, 183, 215]]], dtype=uint8), 'Pink-Lady_024.jpg': array([[[ 14,  33,  46],\n",
       "        [ 11,  37,  53],\n",
       "        [ 25,  66,  88],\n",
       "        ...,\n",
       "        [101, 113, 141],\n",
       "        [102, 116, 144],\n",
       "        [105, 119, 147]],\n",
       "\n",
       "       [[ 10,  29,  42],\n",
       "        [ 10,  36,  52],\n",
       "        [ 30,  69,  91],\n",
       "        ...,\n",
       "        [101, 114, 140],\n",
       "        [ 99, 114, 140],\n",
       "        [ 99, 114, 140]],\n",
       "\n",
       "       [[  8,  25,  38],\n",
       "        [  9,  34,  50],\n",
       "        [ 30,  67,  89],\n",
       "        ...,\n",
       "        [ 97, 111, 133],\n",
       "        [ 89, 106, 127],\n",
       "        [ 84, 101, 122]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 33,  44,  66],\n",
       "        [ 35,  46,  68],\n",
       "        [ 37,  48,  70],\n",
       "        ...,\n",
       "        [ 33,  41,  71],\n",
       "        [ 33,  40,  73],\n",
       "        [ 33,  40,  73]],\n",
       "\n",
       "       [[ 34,  45,  67],\n",
       "        [ 35,  46,  68],\n",
       "        [ 37,  48,  70],\n",
       "        ...,\n",
       "        [ 33,  41,  71],\n",
       "        [ 33,  40,  73],\n",
       "        [ 33,  40,  73]],\n",
       "\n",
       "       [[ 34,  45,  67],\n",
       "        [ 35,  46,  68],\n",
       "        [ 37,  48,  70],\n",
       "        ...,\n",
       "        [ 33,  41,  71],\n",
       "        [ 33,  40,  73],\n",
       "        [ 33,  40,  73]]], dtype=uint8), 'Pink-Lady_025.jpg': array([[[ 51,  70, 113],\n",
       "        [ 52,  71, 116],\n",
       "        [ 52,  70, 117],\n",
       "        ...,\n",
       "        [ 56,  48, 189],\n",
       "        [ 57,  47, 184],\n",
       "        [ 56,  47, 181]],\n",
       "\n",
       "       [[ 52,  71, 114],\n",
       "        [ 53,  72, 115],\n",
       "        [ 53,  71, 118],\n",
       "        ...,\n",
       "        [ 49,  40, 184],\n",
       "        [ 54,  43, 183],\n",
       "        [ 54,  44, 180]],\n",
       "\n",
       "       [[ 53,  73, 114],\n",
       "        [ 54,  73, 116],\n",
       "        [ 54,  72, 119],\n",
       "        ...,\n",
       "        [ 46,  36, 183],\n",
       "        [ 54,  41, 186],\n",
       "        [ 55,  43, 185]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 11,  16,  19],\n",
       "        [ 12,  17,  20],\n",
       "        [ 13,  18,  21],\n",
       "        ...,\n",
       "        [129, 121, 208],\n",
       "        [131, 123, 206],\n",
       "        [111, 102, 183]],\n",
       "\n",
       "       [[ 11,  16,  19],\n",
       "        [ 12,  17,  20],\n",
       "        [ 13,  18,  21],\n",
       "        ...,\n",
       "        [ 90,  80, 173],\n",
       "        [100,  89, 181],\n",
       "        [104,  93, 185]],\n",
       "\n",
       "       [[ 11,  16,  19],\n",
       "        [ 12,  17,  20],\n",
       "        [ 13,  18,  21],\n",
       "        ...,\n",
       "        [ 90,  79, 176],\n",
       "        [ 89,  77, 173],\n",
       "        [ 91,  79, 175]]], dtype=uint8), 'Red-Delicious_002.jpg': array([[[118, 119, 163],\n",
       "        [136, 138, 179],\n",
       "        [137, 139, 180],\n",
       "        ...,\n",
       "        [ 32,  36, 155],\n",
       "        [ 33,  37, 155],\n",
       "        [ 35,  39, 157]],\n",
       "\n",
       "       [[ 92,  93, 137],\n",
       "        [131, 133, 174],\n",
       "        [147, 149, 190],\n",
       "        ...,\n",
       "        [ 32,  36, 155],\n",
       "        [ 33,  37, 155],\n",
       "        [ 33,  37, 155]],\n",
       "\n",
       "       [[ 57,  58, 102],\n",
       "        [118, 120, 161],\n",
       "        [153, 155, 196],\n",
       "        ...,\n",
       "        [ 32,  36, 155],\n",
       "        [ 31,  35, 153],\n",
       "        [ 31,  35, 153]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 57, 191, 221],\n",
       "        [ 58, 192, 222],\n",
       "        [ 59, 193, 223],\n",
       "        ...,\n",
       "        [ 24,  83, 162],\n",
       "        [ 25,  84, 163],\n",
       "        [ 23,  85, 163]],\n",
       "\n",
       "       [[ 49, 189, 220],\n",
       "        [ 51, 191, 222],\n",
       "        [ 52, 192, 223],\n",
       "        ...,\n",
       "        [ 28,  88, 164],\n",
       "        [ 29,  88, 167],\n",
       "        [ 29,  88, 167]],\n",
       "\n",
       "       [[ 45, 188, 219],\n",
       "        [ 47, 190, 221],\n",
       "        [ 48, 191, 222],\n",
       "        ...,\n",
       "        [ 32,  90, 166],\n",
       "        [ 31,  90, 169],\n",
       "        [ 32,  91, 170]]], dtype=uint8), 'Red-Delicious_003.jpg': array([[[ 61,  88, 114],\n",
       "        [  7,  33,  57],\n",
       "        [  0,   9,  27],\n",
       "        ...,\n",
       "        [182, 206, 226],\n",
       "        [181, 205, 225],\n",
       "        [180, 204, 224]],\n",
       "\n",
       "       [[ 58,  82, 104],\n",
       "        [  5,  29,  49],\n",
       "        [  0,   6,  23],\n",
       "        ...,\n",
       "        [182, 206, 226],\n",
       "        [181, 205, 225],\n",
       "        [180, 204, 224]],\n",
       "\n",
       "       [[ 58,  78,  95],\n",
       "        [  8,  27,  42],\n",
       "        [  0,   7,  20],\n",
       "        ...,\n",
       "        [179, 203, 223],\n",
       "        [178, 202, 222],\n",
       "        [177, 201, 221]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  7,  13,  32],\n",
       "        [  6,  10,  34],\n",
       "        [  5,   7,  37],\n",
       "        ...,\n",
       "        [ 44,  53,  67],\n",
       "        [ 42,  51,  65],\n",
       "        [ 43,  52,  66]],\n",
       "\n",
       "       [[  5,  10,  25],\n",
       "        [  2,   8,  27],\n",
       "        [  1,   5,  30],\n",
       "        ...,\n",
       "        [ 78,  85, 100],\n",
       "        [ 60,  67,  82],\n",
       "        [ 50,  58,  71]],\n",
       "\n",
       "       [[  3,   9,  22],\n",
       "        [  2,   7,  22],\n",
       "        [  0,   3,  27],\n",
       "        ...,\n",
       "        [121, 128, 143],\n",
       "        [ 89,  95, 108],\n",
       "        [ 67,  73,  86]]], dtype=uint8), 'Red-Delicious_009.jpg': array([[[ 59, 109, 155],\n",
       "        [ 38,  88, 134],\n",
       "        [ 48,  97, 141],\n",
       "        ...,\n",
       "        [ 86,  94, 177],\n",
       "        [ 85,  96, 176],\n",
       "        [ 87,  98, 178]],\n",
       "\n",
       "       [[ 56, 106, 152],\n",
       "        [ 35,  85, 131],\n",
       "        [ 42,  91, 135],\n",
       "        ...,\n",
       "        [ 82,  91, 171],\n",
       "        [ 84,  93, 173],\n",
       "        [ 84,  96, 174]],\n",
       "\n",
       "       [[ 54, 104, 150],\n",
       "        [ 34,  84, 130],\n",
       "        [ 35,  84, 130],\n",
       "        ...,\n",
       "        [ 79,  86, 165],\n",
       "        [ 82,  90, 167],\n",
       "        [ 83,  93, 170]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 22,  17, 109],\n",
       "        [ 22,  17, 109],\n",
       "        [ 22,  17, 108],\n",
       "        ...,\n",
       "        [ 21, 135, 205],\n",
       "        [ 17, 131, 202],\n",
       "        [ 15, 129, 200]],\n",
       "\n",
       "       [[ 22,  14, 109],\n",
       "        [ 22,  14, 107],\n",
       "        [ 23,  16, 107],\n",
       "        ...,\n",
       "        [ 25, 137, 207],\n",
       "        [ 21, 132, 204],\n",
       "        [ 19, 130, 202]],\n",
       "\n",
       "       [[ 21,  13, 108],\n",
       "        [ 21,  13, 106],\n",
       "        [ 21,  13, 106],\n",
       "        ...,\n",
       "        [ 26, 138, 208],\n",
       "        [ 22, 133, 205],\n",
       "        [ 21, 132, 204]]], dtype=uint8), 'Red-Delicious_010.jpg': array([[[  0, 134, 206],\n",
       "        [  3, 132, 205],\n",
       "        [  8, 130, 206],\n",
       "        ...,\n",
       "        [ 77, 130, 163],\n",
       "        [ 73, 121, 155],\n",
       "        [ 68, 116, 150]],\n",
       "\n",
       "       [[ 12, 131, 200],\n",
       "        [ 13, 130, 199],\n",
       "        [ 19, 127, 198],\n",
       "        ...,\n",
       "        [ 75, 128, 161],\n",
       "        [ 70, 121, 154],\n",
       "        [ 65, 113, 147]],\n",
       "\n",
       "       [[ 31, 123, 182],\n",
       "        [ 32, 122, 181],\n",
       "        [ 35, 118, 179],\n",
       "        ...,\n",
       "        [ 79, 131, 167],\n",
       "        [ 72, 122, 158],\n",
       "        [ 60, 110, 146]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[228, 246, 253],\n",
       "        [228, 246, 253],\n",
       "        [228, 246, 253],\n",
       "        ...,\n",
       "        [176, 195, 216],\n",
       "        [178, 197, 218],\n",
       "        [179, 198, 219]],\n",
       "\n",
       "       [[228, 246, 253],\n",
       "        [228, 246, 253],\n",
       "        [228, 246, 253],\n",
       "        ...,\n",
       "        [153, 171, 194],\n",
       "        [154, 172, 195],\n",
       "        [156, 174, 197]],\n",
       "\n",
       "       [[228, 246, 253],\n",
       "        [228, 246, 253],\n",
       "        [228, 246, 253],\n",
       "        ...,\n",
       "        [147, 165, 188],\n",
       "        [148, 166, 189],\n",
       "        [149, 167, 190]]], dtype=uint8), 'Royal-Gala_058.jpg': array([[[ 14,  22,  29],\n",
       "        [ 14,  22,  29],\n",
       "        [ 14,  22,  29],\n",
       "        ...,\n",
       "        [  3,   5,  13],\n",
       "        [  5,   7,  15],\n",
       "        [  8,  10,  18]],\n",
       "\n",
       "       [[ 14,  22,  29],\n",
       "        [ 14,  22,  29],\n",
       "        [ 14,  22,  29],\n",
       "        ...,\n",
       "        [  3,   5,  13],\n",
       "        [  5,   7,  15],\n",
       "        [  7,   9,  17]],\n",
       "\n",
       "       [[ 17,  25,  32],\n",
       "        [ 17,  25,  32],\n",
       "        [ 17,  25,  32],\n",
       "        ...,\n",
       "        [  4,   6,  14],\n",
       "        [  6,   8,  16],\n",
       "        [  8,  10,  18]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 52,  51, 143],\n",
       "        [ 46,  45, 137],\n",
       "        [ 39,  39, 129],\n",
       "        ...,\n",
       "        [ 57,  92, 202],\n",
       "        [ 66,  99, 208],\n",
       "        [ 73, 106, 215]],\n",
       "\n",
       "       [[ 68,  67, 159],\n",
       "        [ 62,  61, 153],\n",
       "        [ 54,  51, 143],\n",
       "        ...,\n",
       "        [ 53,  86, 196],\n",
       "        [ 61,  92, 201],\n",
       "        [ 69, 100, 209]],\n",
       "\n",
       "       [[ 81,  80, 172],\n",
       "        [ 75,  74, 166],\n",
       "        [ 66,  63, 155],\n",
       "        ...,\n",
       "        [ 53,  86, 196],\n",
       "        [ 60,  91, 200],\n",
       "        [ 67,  98, 207]]], dtype=uint8), 'Royal-Gala_059.jpg': array([[[ 41, 121, 214],\n",
       "        [ 43, 121, 214],\n",
       "        [ 50, 125, 217],\n",
       "        ...,\n",
       "        [ 15,  18,  92],\n",
       "        [ 10,  15,  90],\n",
       "        [  9,  14,  89]],\n",
       "\n",
       "       [[ 47, 125, 218],\n",
       "        [ 44, 122, 215],\n",
       "        [ 48, 123, 215],\n",
       "        ...,\n",
       "        [ 14,  19,  94],\n",
       "        [ 19,  23, 101],\n",
       "        [ 24,  28, 106]],\n",
       "\n",
       "       [[ 53, 130, 223],\n",
       "        [ 46, 123, 216],\n",
       "        [ 46, 119, 211],\n",
       "        ...,\n",
       "        [ 29,  33, 111],\n",
       "        [ 42,  46, 125],\n",
       "        [ 50,  55, 134]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 51,  64, 150],\n",
       "        [ 48,  58, 145],\n",
       "        [ 41,  51, 138],\n",
       "        ...,\n",
       "        [ 29,  33,  34],\n",
       "        [ 28,  32,  33],\n",
       "        [ 27,  31,  32]],\n",
       "\n",
       "       [[ 57,  73, 156],\n",
       "        [ 53,  69, 152],\n",
       "        [ 49,  63, 146],\n",
       "        ...,\n",
       "        [ 21,  23,  24],\n",
       "        [ 20,  22,  23],\n",
       "        [ 19,  21,  22]],\n",
       "\n",
       "       [[ 61,  79, 162],\n",
       "        [ 57,  75, 158],\n",
       "        [ 55,  69, 152],\n",
       "        ...,\n",
       "        [ 14,  16,  17],\n",
       "        [ 13,  15,  16],\n",
       "        [ 13,  15,  16]]], dtype=uint8), 'Royal-Gala_065.jpg': array([[[  0, 114, 117],\n",
       "        [  0, 120, 123],\n",
       "        [  1, 137, 141],\n",
       "        ...,\n",
       "        [ 81, 185, 222],\n",
       "        [ 70, 176, 213],\n",
       "        [ 63, 169, 206]],\n",
       "\n",
       "       [[  0, 125, 128],\n",
       "        [  0, 128, 131],\n",
       "        [  5, 141, 145],\n",
       "        ...,\n",
       "        [ 91, 192, 231],\n",
       "        [ 82, 185, 224],\n",
       "        [ 77, 180, 219]],\n",
       "\n",
       "       [[  1, 142, 145],\n",
       "        [  1, 142, 145],\n",
       "        [ 11, 150, 153],\n",
       "        ...,\n",
       "        [ 95, 190, 233],\n",
       "        [ 88, 185, 229],\n",
       "        [ 84, 183, 227]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 19,  24,  25],\n",
       "        [ 19,  24,  25],\n",
       "        [ 19,  24,  25],\n",
       "        ...,\n",
       "        [ 35,  30, 139],\n",
       "        [ 36,  30, 141],\n",
       "        [ 37,  31, 142]],\n",
       "\n",
       "       [[ 19,  24,  25],\n",
       "        [ 19,  24,  25],\n",
       "        [ 19,  24,  25],\n",
       "        ...,\n",
       "        [ 38,  32, 139],\n",
       "        [ 38,  33, 142],\n",
       "        [ 38,  33, 142]],\n",
       "\n",
       "       [[ 19,  24,  25],\n",
       "        [ 19,  24,  25],\n",
       "        [ 19,  24,  25],\n",
       "        ...,\n",
       "        [ 39,  33, 140],\n",
       "        [ 39,  34, 143],\n",
       "        [ 40,  35, 144]]], dtype=uint8)}, annotations={'0_100 (10).jpg': Detections(xyxy=array([[     1.5699,      1.1521,      99.089,      98.419]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.88839], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '0_100.jpg': Detections(xyxy=array([[    0.17649,     0.56783,      99.623,      99.012]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([     0.8972], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '10_100 (11).jpg': Detections(xyxy=array([[     1.0489,     0.74074,      98.068,      97.667]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True]]]), confidence=array([    0.88367], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '10_100 (7).jpg': Detections(xyxy=array([[     4.4062,      1.3861,      94.362,      99.545]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.89771], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '13_100 (7).jpg': Detections(xyxy=array([[     4.6749,  -0.0062866,      94.416,       99.96]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.89869], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '1_100 (10).jpg': Detections(xyxy=array([[     1.5846,      1.4536,      98.215,       98.56]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.87749], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '1_100.jpg': Detections(xyxy=array([[    0.38913,     0.54129,      99.741,      98.955]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.91246], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), '9_100.jpg': Detections(xyxy=array([[    0.18261,     0.60677,      99.463,      99.054]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ..., False, False,  True],\n",
       "        [False, False, False, ..., False, False,  True]]]), confidence=array([    0.90321], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), 'Pink-Lady_017.jpg': Detections(xyxy=array([[ 0.00045776,   0.0020752,         348,         348]], dtype=float32), mask=array([[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True, False, ..., False, False, False],\n",
       "        [ True, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]]), confidence=array([    0.35964], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), 'Pink-Lady_018.jpg': Detections(xyxy=array([[   0.080444,   -0.046188,      348.08,      347.95]], dtype=float32), mask=array([[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ...,  True,  True,  True]]]), confidence=array([     0.3568], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), 'Pink-Lady_024.jpg': Detections(xyxy=array([[     56.675,      306.53,       119.9,      348.02],\n",
       "       [     131.73,      311.36,      184.12,      348.02],\n",
       "       [  -0.027971,      317.52,      17.462,      348.07]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False]]]), confidence=array([    0.37711,     0.35542,     0.35719], dtype=float32), class_id=array([0, 0, 0], dtype=int64), tracker_id=None), 'Pink-Lady_025.jpg': Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=array([], dtype=float64), confidence=array([], dtype=float32), class_id=array([], dtype=int64), tracker_id=None), 'Red-Delicious_002.jpg': Detections(xyxy=array([[   0.057343,   -0.045273,      348.06,      347.95]], dtype=float32), mask=array([[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True]]]), confidence=array([    0.35479], dtype=float32), class_id=array([0], dtype=int64), tracker_id=None), 'Red-Delicious_003.jpg': Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=array([], dtype=float64), confidence=array([], dtype=float32), class_id=array([], dtype=int64), tracker_id=None), 'Red-Delicious_009.jpg': Detections(xyxy=array([[     253.15,      144.61,      348.03,      248.71],\n",
       "       [      17.56,      75.593,      86.096,      136.76],\n",
       "       [     182.31,      57.857,      249.84,      128.76],\n",
       "       [     3.0363,      133.83,      77.844,      200.64],\n",
       "       [     112.45,    -0.02494,      179.04,      56.738],\n",
       "       [  0.0078316,      116.17,      17.155,      174.23],\n",
       "       [     185.08,      218.26,      284.93,      309.95],\n",
       "       [     73.806,      149.36,      147.38,      226.64],\n",
       "       [     282.84,   -0.065907,      347.93,      36.916],\n",
       "       [  -0.025658,       196.3,      73.548,      265.39],\n",
       "       [     80.738,      44.114,      127.92,      97.878],\n",
       "       [     280.53,      303.61,      348.01,      348.06],\n",
       "       [     79.079,      95.583,      136.83,      152.45],\n",
       "       [     336.64,  -0.0093212,      347.99,      49.651],\n",
       "       [     218.93,      137.48,      279.78,      180.65]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.38861,     0.37824,     0.37712,     0.38786,     0.38634,      0.4174,     0.36556,     0.36017,     0.36086,     0.35686,     0.36795,     0.35303,     0.35399,     0.35766,     0.35978], dtype=float32), class_id=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), tracker_id=None), 'Red-Delicious_010.jpg': Detections(xyxy=array([[     278.32,      259.23,         348,      329.42],\n",
       "       [     11.336,      235.33,      77.356,      299.39],\n",
       "       [      71.57,      232.01,      164.15,      309.99],\n",
       "       [     33.423,      168.98,      102.66,       237.6],\n",
       "       [      213.5,      218.56,      288.03,      291.48],\n",
       "       [     270.83,      83.651,       333.6,      140.67],\n",
       "       [      211.2,      108.62,      275.48,      165.32],\n",
       "       [      156.9,      181.77,      224.91,      249.33],\n",
       "       [     217.12,      162.45,      286.41,      219.13],\n",
       "       [     277.89,      133.94,      347.92,      193.79],\n",
       "       [     157.01,      247.63,      225.47,      316.71],\n",
       "       [     51.705,      125.35,      114.35,      178.49],\n",
       "       [      277.2,      188.23,      347.98,      259.92],\n",
       "       [     273.01,      43.773,      332.85,      88.142],\n",
       "       [     179.88,      9.8584,      231.05,      50.389],\n",
       "       [     102.32,      149.68,      164.27,      206.95],\n",
       "       [     163.16,      129.62,      222.95,      190.69],\n",
       "       [      90.56,      205.56,      161.75,      249.35]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.46132,     0.44778,     0.38711,       0.386,     0.38226,     0.37781,     0.35846,     0.35705,     0.36287,     0.38447,     0.40435,     0.35871,     0.39381,     0.35413,     0.35334,     0.35621,     0.35683,     0.38132], dtype=float32), class_id=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), tracker_id=None), 'Royal-Gala_058.jpg': Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=array([], dtype=float64), confidence=array([], dtype=float32), class_id=array([], dtype=int64), tracker_id=None), 'Royal-Gala_059.jpg': Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=array([], dtype=float64), confidence=array([], dtype=float32), class_id=array([], dtype=int64), tracker_id=None), 'Royal-Gala_065.jpg': Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=array([], dtype=float64), confidence=array([], dtype=float32), class_id=array([], dtype=int64), tracker_id=None)})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autodistill_grounded_sam import GroundedSAM\n",
    "from autodistill.detection import CaptionOntology\n",
    "from autodistill_yolov8 import YOLOv8\n",
    "\n",
    "# define an ontology to map class names to our GroundingDINO prompt\n",
    "# the ontology dictionary has the format {caption: class}\n",
    "# where caption is the prompt sent to the base model, and class is the label that will\n",
    "# be saved for that caption in the generated annotations\n",
    "base_model = GroundedSAM(ontology=CaptionOntology({\"Apple\": \"Apple\",\n",
    "                                                  }))\n",
    "\n",
    "# label all images in a folder called `context_images`\n",
    "base_model.label(\n",
    "  input_folder = \"D:\\\\ML\\\\xyz\",\n",
    "  output_folder= \"D:\\\\ML\\\\label_apple\"\n",
    ")\n",
    "\n",
    "# target_model = YOLOv8(\"yolov8n.pt\")\n",
    "# target_model.train(\"./dataset/data.yaml\", epochs=200)\n",
    "\n",
    "# run inference on the new model\n",
    "# pred = target_model.predict(\"./dataset/valid/your-image.jpg\", confidence=0.5)\n",
    "# print(pred)\n",
    "\n",
    "# optional: upload your model to Roboflow for deployment\n",
    "# from roboflow import Roboflow\n",
    "\n",
    "# rf = Roboflow(api_key=\"API_KEY\")\n",
    "# project = rf.workspace().project(\"PROJECT_ID\")\n",
    "# project.version(DATASET_VERSION).deploy(model_type=\"yolov8\", model_path=f\"./runs/detect/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.17  Python-3.12.3 torch-2.4.1+cu124 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=gpu' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): True\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: None\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautodistill_yolov8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLOv8\n\u001b[0;32m      5\u001b[0m target_model \u001b[38;5;241m=\u001b[39m YOLOv8(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mML\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mYOLOV\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFruit_11\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autodistill_yolov8\\yolov8.py:43\u001b[0m, in \u001b[0;36mYOLOv8.train\u001b[1;34m(self, dataset_yaml, epochs, device)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_yaml, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    794\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:103\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(cfg, overrides)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_resume(overrides)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\torch_utils.py:192\u001b[0m, in \u001b[0;36mselect_device\u001b[1;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[0;32m    185\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39minfo(s)\n\u001b[0;32m    186\u001b[0m         install \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requested.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or pass valid CUDA device(s) if available,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0,1,2,3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     devices \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid CUDA 'device=gpu' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): True\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: None\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "from autodistill_grounded_sam import GroundedSAM\n",
    "from autodistill.detection import CaptionOntology\n",
    "from autodistill_yolov8 import YOLOv8\n",
    "\n",
    "target_model = YOLOv8(\"yolov8s.pt\")\n",
    "target_model.train(\"D:\\\\ML\\\\YOLOV\\\\Fruit_11\\\\data.yaml\", epochs=50 , device = 'gpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.17  Python-3.12.3 torch-2.4.1+cu124 CPU (AMD Ryzen 7 6800HS with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=D:\\ML\\YOLOV\\Fruit_11\\data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train17\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    433597  ultralytics.nn.modules.head.Detect           [15, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,592,765 parameters, 2,592,749 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train17', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ML\\YOLOV\\Fruit_11\\train\\labels.cache... 4010 images, 10 backgrounds, 0 corrupt: 100%|██████████| 4010/4010 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ML\\YOLOV\\Fruit_11\\valid\\labels.cache... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train17\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train17\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.449       4.04      1.771        103        640:   5%|▍         | 12/251 [00:41<13:46,  3.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m target_model \u001b[38;5;241m=\u001b[39m YOLO()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mML\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mYOLOV\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFruit_11\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:802\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:393\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    389\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jayme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "target_model = YOLO()\n",
    "target_model.train(data =\"D:\\\\ML\\\\YOLOV\\\\Fruit_11\\\\data.yaml\", epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
